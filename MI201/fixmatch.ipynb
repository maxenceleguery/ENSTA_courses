{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h-hHvqBUj2Gd"},"outputs":[],"source":["import copy\n","from numpy import asarray\n","import os\n","import glob\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","import torchvision.models as models\n","from torchvision import transforms\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","import torchvision\n","import random\n","import math\n","from torch.autograd import Variable\n","from torch.nn.functional import kl_div, softmax, log_softmax\n","import torch.optim as optim\n","import torch.utils.data as data\n","from os.path import exists, join, split\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageFilter , ImageDraw\n","import PIL\n","import random\n","import matplotlib.pyplot as plt\n","#! pip install madgrad\n","#! pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hc-jpcWqqnt0"},"outputs":[],"source":["# Hyperparameters\n","\n","num_class = 10 # Number of classes\n","seed=111 # Seed for the algorithm\n","batch_size = 32\n","num_train = 100 # Number of training image by classe\n","cutout=16  # Parameter for the cutout\n","num_epochs=20\n","valid_size = 200 # Validation set size\n","lr=0.001 # Learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2140,"status":"ok","timestamp":1677684705881,"user":{"displayName":"Maxence Leguéry","userId":"05586363970004812313"},"user_tz":-60},"id":"KLL-QYPnqrOS","outputId":"8206c11e-731b-4df6-d405-d10870cba06a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Number of training examples: 1000\n","Number of unlabeled examples: 47000\n","Number of validation examples: 2000\n","mu = 47\n"]}],"source":["class Dataset_sub_CIFAR(data.Dataset):\n","\n","    def __init__(self, data_feature, data_target,transform,phase='label'):\n","        self.data_feature = data_feature\n","        self.data_target = data_target\n","        self.transform = transform\n","        self.phase=phase\n","\n","    def __len__(self):\n","        return len(self.data_feature)\n","\n","    def __getitem__(self, index):\n","        if self.phase=='label':\n","            data_feature = self.transform(Image.fromarray(np.uint8(self.data_feature[index])))\n","            data_target =  self.data_target[index]\n","            return data_feature, data_target\n","\n","        else:\n","            data_feature = self.data_feature[index].float()\n","            return data_feature\n","\n","no_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(128),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","weak_augmentation = transforms.Compose([\n","    transforms.Resize(128),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","])\n","\n","strong_augmentation = transforms.Compose([\n","    transforms.Resize(128),\n","    transforms.RandomCrop(size=128,padding=int(128*0.125),padding_mode='reflect'),\n","])\n","\n","\n","#Dataset loading\n","CIFAR10_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=None, download=True)\n","CIFAR10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=None, download=True)\n","np.random.seed(seed=seed)\n","permuation=np.random.permutation(len(CIFAR10_train_dataset.targets))\n","\n","Original_train_data_x = (CIFAR10_train_dataset.data)\n","Original_train_data_y = np.array(CIFAR10_train_dataset.targets)\n","Original_train_data_x = Original_train_data_x[permuation]\n","Original_train_data_y = Original_train_data_y[permuation]\n","\n","Original_test_data_x = CIFAR10_test_dataset.data\n","Original_test_data_y = np.array(CIFAR10_test_dataset.targets)\n","\n","incr_class = torch.zeros(num_class)\n","train_idx_dico = {} #labeled images index dictionnary\n","\n","for i in range(num_class):\n","    train_idx_dico[str(i)] = []\n","\n","valid_idx = np.zeros(num_class * valid_size, dtype=np.int32) #validation images indexes (2000)\n","incr_t = 0\n","incr_v = 0\n","incrtotal = 0\n","\n","for idx in range(len(Original_train_data_y)):\n","    class_y = Original_train_data_y[idx]\n","    incrtotal += 1\n","\n","    train_idx_dico[str(class_y)].append(idx)\n","    incr_class[class_y] += 1 #count the number of image per class\n","    incr_t += 1\n","\n","\n","train_idx = np.zeros(num_class * num_train, dtype=np.int32) #train labeled images indexes (1000)\n","list_train_id = []\n","list_unalabel_id = []\n","valid_idx = []\n","unlabel_idx_dico = {}\n","for i in range(num_class):\n","    unlabel_idx_dico[str(i)] = []\n","for i in range(num_class):\n","    list_train_id = list_train_id + train_idx_dico[str(i)][0:num_train]\n","    valid_idx =valid_idx + train_idx_dico[str(i)][num_train:num_train+valid_size]\n","    list_unalabel_id = list_unalabel_id + train_idx_dico[str(i)][num_train+valid_size::]\n","    unlabel_idx_dico[str(i)] = train_idx_dico[str(i)][num_train::]\n","\n","#Get labeled and unlabeled data\n","\n","x_train = Original_train_data_x[[int(i) for i in list_train_id]]\n","y_train = Original_train_data_y[[int(i) for i in list_train_id]]\n","\n","x_unlabeled = Original_train_data_x[[int(i) for i in list_unalabel_id]]\n","y_unlabeled = Original_train_data_y[[int(i) for i in list_unalabel_id]]\n","\n","#Get validation set data\n","x_valid = Original_train_data_x[[int(i) for i in valid_idx]]\n","y_valid = Original_train_data_y[[int(i) for i in valid_idx]]\n","\n","# Printing the size of the training, validation and test sets\n","print('Semi-supervised training')\n","print('Number of training examples: ' + str(x_train.shape[0]))\n","print('Number of unlabeled examples: ' + str(x_unlabeled.shape[0]))\n","print('Number of validation examples: ' + str(x_valid.shape[0]))\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","#Dataloader creation\n","\n","test_loader = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_test),\n","    batch_size = batch_size,\n","    shuffle=False, num_workers=2)\n","\n","valid_loader = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(x_valid, y_valid, transform=transform_test),\n","    batch_size=batch_size,\n","    shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eh-kQigTq0rs"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","def learning_rate_scheduler(init, k):\n","    return init #Version that does not change with respect to epoch\n","    optim_factor = 0\n","    if(k > 20):\n","        optim_factor = 5\n","    elif(k > 15):\n","        optim_factor = 4\n","    elif(k > 10):\n","        optim_factor = 3\n","    elif(k > 7):\n","        optim_factor = 2\n","    elif(k > 5):\n","        optim_factor = 1\n","\n","    return init*math.pow(0.1, optim_factor)\n","\n","\n","# Training\n","def trainSupervised(epoch,net,trainloader,k):\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    print('\\n=> Training Epoch #%d, LR=%.4f, k=%.d' %(epoch, learning_rate_scheduler(lr, k),k))\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate_scheduler(lr, k), momentum=0.9, weight_decay=5e-4,nesterov=True)\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","\n","      inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n","      optimizer.zero_grad()\n","      inputs, targets = Variable(inputs), Variable(targets)\n","      outputs = net(strong_augmentation(inputs)) # Forward Propagation\n","      loss = criterion(outputs, targets)  # Loss\n","      loss.backward()  # Backward Propagation\n","      optimizer.step() # Optimizer update\n","\n","      train_loss += loss.item()\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += targets.size(0)\n","      correct += predicted.eq(targets.data).cpu().sum()\n","      if batch_idx % 15 == 0:\n","        print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%' %(epoch, num_epochs, batch_idx+1, (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct/total))\n","\n","def test(epoch,net,test_loader):\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","      for batch_idx, (inputs, targets) in enumerate(test_loader):\n","        inputs, targets = inputs.cuda(), targets.cuda()\n","        inputs, targets = Variable(inputs), Variable(targets)\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        test_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","        \n","    acc = 100.*correct/total\n","    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\\nBest accuracy yet : %.2f%%\" %(epoch, loss.item(), acc, best_acc))\n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":816},"id":"1u9fgmGCq7b1","outputId":"7f899104-63c7-441b-d4b5-8bcee9021a30","executionInfo":{"status":"error","timestamp":1677684717538,"user_tz":-60,"elapsed":11662,"user":{"displayName":"Maxence Leguéry","userId":"05586363970004812313"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=> Training Epoch #0, LR=0.0010, k=0\n","| Epoch [  0/ 20] Iter[  1/ 32]\t\tLoss: 2.5696 Acc@1: 12.500%\n","| Epoch [  0/ 20] Iter[ 16/ 32]\t\tLoss: 1.9422 Acc@1: 17.773%\n","| Epoch [  0/ 20] Iter[ 31/ 32]\t\tLoss: 1.3338 Acc@1: 30.645%\n","\n","| Validation Epoch #0\t\t\tLoss: 0.6322 Acc@1: 55.85%\n","Best accuracy yet : 0.00%\n","| Saving Best model...\t\t\tTop1 = 55.85%\n","\n","\n","=> Training Epoch #1, LR=0.0010, k=0\n","| Epoch [  1/ 20] Iter[  1/ 32]\t\tLoss: 1.2732 Acc@1: 65.625%\n","| Epoch [  1/ 20] Iter[ 16/ 32]\t\tLoss: 1.2038 Acc@1: 63.477%\n","| Epoch [  1/ 20] Iter[ 31/ 32]\t\tLoss: 0.8799 Acc@1: 66.230%\n","\n","| Validation Epoch #1\t\t\tLoss: 0.3482 Acc@1: 69.45%\n","Best accuracy yet : 55.85%\n","| Saving Best model...\t\t\tTop1 = 69.45%\n","\n","\n","=> Training Epoch #2, LR=0.0010, k=0\n","| Epoch [  2/ 20] Iter[  1/ 32]\t\tLoss: 0.6825 Acc@1: 81.250%\n","| Epoch [  2/ 20] Iter[ 16/ 32]\t\tLoss: 0.7670 Acc@1: 78.906%\n","| Epoch [  2/ 20] Iter[ 31/ 32]\t\tLoss: 0.8438 Acc@1: 78.427%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f3f90280d3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m#Training supervisé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m   \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m#Pseudo-labelisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-f3f90280d3ae>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(net, train_loader, k)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrainSupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Save checkpoint when best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1bf94eb5ca6b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch, net, test_loader)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["best_acc=0\n","weights = models.ResNet18_Weights.DEFAULT\n","\n","net = models.resnet18(weights=weights)\n","net_save = models.resnet18(weights=weights)\n","\n","net.fc = nn.Linear(net.fc.in_features, num_class) # Setting the number of output neurones to the number of different classes\n","net.fc = net.fc.cuda()\n","\n","net_save.fc = nn.Linear(net_save.fc.in_features, num_class)\n","net_save.fc = net_save.fc.cuda()\n","\n","net = net.cuda()\n","net_save = net_save.cuda()\n","\n","tau=0.98 # threshold for fixmatch\n","\n","train_loader = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(x_train, y_train, transform=no_transform),\n","    batch_size=batch_size,shuffle=True, num_workers=2)\n","\n","train_loader_unlabel = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(x_unlabeled, y_unlabeled, transform=no_transform),\n","    batch_size=batch_size,shuffle=False, num_workers=2)\n","\n","epochs=[]\n","accuracies=[]\n","\n","def trainNetwork(net,train_loader,k):\n","  global best_acc\n","  num_epochs=20\n","  for epoch in range(num_epochs):\n","    trainSupervised(epoch,net,train_loader,k)\n","    acc=test(epoch,net,valid_loader)\n","    # Save checkpoint when best model\n","    if acc > best_acc:\n","        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%\\n' %(acc))\n","        net_save.load_state_dict(net.state_dict(), strict=True)\n","        best_acc=acc\n","    epochs.append(epoch+num_epochs*k)\n","    accuracies.append(best_acc)\n","\n","indexDone=[]\n","\n","for k in range(3):\n","  #Supervised Training\n","  trainNetwork(net,train_loader,k)\n","\n","  #Pseudo-labelization\n","\n","  print('=> Pseudo-labelization')\n","  for batch_idx, (inputsCPU, targetsCPU) in enumerate(train_loader_unlabel):\n","    net.eval()\n","    inputs, targets = inputsCPU.cuda(), targetsCPU.cuda()\n","\n","    out1 = net(weak_augmentation(inputs))\n","    pseudo_label1 = torch.softmax(out1, dim=-1)\n","    max_probs1, targets_u1 = torch.max(pseudo_label1, dim=-1)\n","    max_probs1 = max_probs1.cpu().detach().numpy()\n","    targets_u1 = torch.tensor(targets_u1.cpu().detach().numpy())\n","    newTarget1 = np.array(targets_u1)\n","\n","    out2 = net(weak_augmentation(inputs))\n","    pseudo_label2 = torch.softmax(out2, dim=-1)\n","    max_probs2, targets_u2 = torch.max(pseudo_label2, dim=-1)\n","    max_probs2 = max_probs2.cpu().detach().numpy()\n","    targets_u2 = torch.tensor(targets_u2.cpu().detach().numpy())\n","    newTarget2 = np.array(targets_u2)\n","\n","    out3 = net(weak_augmentation(inputs))\n","    pseudo_label3 = torch.softmax(out3, dim=-1)\n","    max_probs3, targets_u3 = torch.max(pseudo_label3, dim=-1)\n","    max_probs3 = max_probs3.cpu().detach().numpy()\n","    targets_u3 = torch.tensor(targets_u3.cpu().detach().numpy())\n","    newTarget3 = np.array(targets_u3)\n","\n","    for j in range(len(max_probs1)):\n","      if max_probs1[j]>tau and max_probs2[j]>tau and max_probs3[j]>tau and newTarget1[j]==newTarget2[j] and newTarget1[j]==newTarget3[j]:\n","        imageIndex = batch_idx*batch_size + j\n","        newInput = x_unlabeled[imageIndex,:,:,:]\n","        \n","        if not (imageIndex in indexDone):\n","          x_train = np.append(x_train,[newInput],0)\n","          y_train = np.append(y_train,newTarget1[j])\n","          indexDone.append(imageIndex)\n","\n","    if batch_idx % 100 == 0:\n","        print('| Iter[%4d/%4d] New label : %3d/%3d possible' %(batch_idx+1,x_unlabeled.shape[0]//batch_size,len(indexDone),x_unlabeled.shape[0]))\n","\n","  train_loader = torch.utils.data.DataLoader(\n","  Dataset_sub_CIFAR(x_train, y_train, transform=no_transform),\n","  batch_size=batch_size,shuffle=True, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DPoHGZirB_u"},"outputs":[],"source":["def test_final(net,testloader):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            \n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            inputs, targets = Variable(inputs), Variable(targets)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets.data).cpu().sum()\n","            if batch_idx == 0:\n","                predicted_concat = predicted.clone()\n","            else:\n","                predicted_concat = torch.cat((predicted_concat, predicted), 0)\n","\n","        # Save checkpoint when best model\n","    acc = 100.*correct/total\n","    print(\"\\n| TEST \\tLoss: %.4f Acc@1: %.2f%%\" %( loss.item(), acc))\n","    return predicted_concat.cpu().numpy()\n","    \n","#redicted_concat = test_final(net,test_loader)\n","#predicted_concat = test_final(net_save,test_loader)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.plot(epochs,accuracies)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}